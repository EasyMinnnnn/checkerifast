"""
duplicate_checker.py

CÃ´ng cá»¥ Streamlit Ä‘á»ƒ kiá»ƒm tra trÃ¹ng há»“ sÆ¡ trÆ°á»›c khi phÃª duyá»‡t.
- Táº­p trung vÃ o dá»¯ liá»‡u Äáº¤T á» (Land) import tá»« file Excel iFast.
- So sÃ¡nh cÃ¡c há»“ sÆ¡ Ä‘ang á»Ÿ tráº¡ng thÃ¡i "PhÃª duyá»‡t" vá»›i cÃ¡c há»“ sÆ¡ "HoÃ n thÃ nh".

Rule trÃ¹ng chÃ­nh:

1) TRÃ™NG Tá»ŒA Äá»˜ (Æ°u tiÃªn, cháº¯c cháº¯n):
   - Tá»a Ä‘á»™ chuáº©n hÃ³a (coord_norm) trÃ¹ng nhau
   - VÃ  'Thá»i Ä‘iá»ƒm thu tháº­p thÃ´ng tin' cá»§a há»“ sÆ¡ PhÃª duyá»‡t > há»“ sÆ¡ HoÃ n thÃ nh
   â†’ LuÃ´n gáº¯n nhÃ£n: Cáº¢NH BÃO TRÃ™NG
   (KhÃ´ng cáº§n xÃ©t NgÆ°á»i táº¡o)

2) TRÃ™NG Äá»ŠA CHá»ˆ (5 cá»™t W,X,Y,Z,AE):
   - TrÃ¹ng 5 thÃ´ng tin:
        Tá»‰nh/ThÃ nh phá»‘
        Quáº­n/Huyá»‡n/Thá»‹ xÃ£
        XÃ£/PhÆ°á»ng
        ÄÆ°á»ng/Phá»‘
        Sá»‘ nhÃ 
   - VÃ  'Thá»i Ä‘iá»ƒm thu tháº­p thÃ´ng tin' cá»§a há»“ sÆ¡ PhÃª duyá»‡t > há»“ sÆ¡ HoÃ n thÃ nh
   - Náº¿u cÃ¹ng NgÆ°á»i táº¡o  â†’ Cáº¢NH BÃO TRÃ™NG
   - Náº¿u khÃ¡c NgÆ°á»i táº¡o â†’ NGHI NGá»œ TRÃ™NG

Káº¿t quáº£ hiá»ƒn thá»‹:
- ID                : ID há»“ sÆ¡ PhÃª duyá»‡t
- NgÆ°á»i táº¡o         : NgÆ°á»i táº¡o há»“ sÆ¡ PhÃª duyá»‡t
- LÃ½ do trÃ¹ng       : Cáº£nh bÃ¡o / Nghi ngá» + mÃ´ táº£ chi tiáº¿t
- Äá»‹a chá»‰/Tá»a Ä‘á»™ trÃ¹ng:
    + Náº¿u trÃ¹ng Ä‘á»‹a chá»‰ â†’ hiá»ƒn thá»‹ Ä‘áº§y Ä‘á»§ Ä‘á»‹a chá»‰: Sá»‘ nhÃ  â€“ ÄÆ°á»ng â€“ XÃ£ â€“ Quáº­n â€“ Tá»‰nh
    + Náº¿u trÃ¹ng tá»a Ä‘á»™ â†’ hiá»ƒn thá»‹ tá»a Ä‘á»™
- ID trÃ¹ng          : cÃ¡c ID HoÃ n thÃ nh trÃ¹ng (ngÄƒn cÃ¡ch '; ')
- NgÆ°á»i táº¡o trÃ¹ng   : NgÆ°á»i táº¡o cá»§a cÃ¡c há»“ sÆ¡ HoÃ n thÃ nh trÃ¹ng
"""

from __future__ import annotations

import io
from typing import Optional, List, Dict, Any

import pandas as pd

# Cho phÃ©p import module nÃ y á»Ÿ mÃ´i trÆ°á»ng khÃ´ng cÃ³ streamlit (vd: test)
try:
    import streamlit as st  # type: ignore
except ImportError:  # pragma: no cover
    st = None  # type: ignore


# ==========================
#  Core checking logic
# ==========================

ADDR_COLS = [
    "Tá»‰nh/ThÃ nh phá»‘",       # W
    "Quáº­n/Huyá»‡n/Thá»‹ xÃ£",    # X
    "XÃ£/PhÆ°á»ng",            # Y
    "ÄÆ°á»ng/Phá»‘",            # Z
    "Sá»‘ nhÃ ",               # AE
]

CREATOR_COL = "NgÆ°á»i táº¡o"                     # cá»™t E
TIME_COL = "Thá»i Ä‘iá»ƒm thu tháº­p thÃ´ng tin"     # cá»™t L
COORD_COL = "Tá»a Ä‘á»™"                          # cá»™t AF


def build_addr_key(row: pd.Series) -> str:
    """Chuáº©n hÃ³a 5 thÃ´ng tin Ä‘á»‹a chá»‰ thÃ nh 1 key Ä‘á»ƒ so sÃ¡nh trÃ¹ng."""
    parts: List[str] = []
    for col in ADDR_COLS:
        val = str(row.get(col, "")).strip().lower()
        parts.append(val)
    return "||".join(parts)


def normalize_coord(value: Any, max_len: int = 8) -> Optional[str]:
    """
    Chuáº©n hÃ³a tá»a Ä‘á»™:
    - TÃ¡ch lat, lon theo dáº¥u ','
    - Cáº¯t bá»›t Ä‘á»™ dÃ i má»—i pháº§n Ä‘á»ƒ báº¯t Ä‘Æ°á»£c case nháº­p thÃªm sá»‘ láº» phÃ­a sau.
      VÃ­ dá»¥:
        '12.670322,108.101062'
        '12.6703222,108.1010623'
      Sau chuáº©n hÃ³a Ä‘á»u thÃ nh:
        '12.670322,108.101062'
    """
    if pd.isna(value):
        return None

    try:
        text = str(value)
        lat_raw, lon_raw = text.split(",")
        lat = lat_raw.strip()
        lon = lon_raw.strip()
        lat = lat[:max_len]
        lon = lon[:max_len]
        return f"{lat},{lon}"
    except Exception:
        return None


def format_address(row: pd.Series) -> str:
    """
    Hiá»ƒn thá»‹ Ä‘á»‹a chá»‰ theo thá»© tá»±:
    Sá»‘ nhÃ  â€“ ÄÆ°á»ng/Phá»‘ â€“ XÃ£/PhÆ°á»ng â€“ Quáº­n/Huyá»‡n/Thá»‹ xÃ£ â€“ Tá»‰nh/ThÃ nh phá»‘
    (tÆ°Æ¡ng á»©ng AE â€“ Z â€“ Y â€“ X â€“ W)
    """
    num = str(row.get("Sá»‘ nhÃ ", "")).strip()
    street = str(row.get("ÄÆ°á»ng/Phá»‘", "")).strip()
    ward = str(row.get("XÃ£/PhÆ°á»ng", "")).strip()
    district = str(row.get("Quáº­n/Huyá»‡n/Thá»‹ xÃ£", "")).strip()
    province = str(row.get("Tá»‰nh/ThÃ nh phá»‘", "")).strip()

    parts = [p for p in [num, street, ward, district, province] if p]
    return " â€“ ".join(parts)


def check_duplicates(df: pd.DataFrame) -> pd.DataFrame:
    """
    Kiá»ƒm tra trÃ¹ng giá»¯a:
    - CÃ¡c há»“ sÆ¡ 'PhÃª duyá»‡t'  (Ä‘ang trÃ¬nh)
    - VÃ  há»“ sÆ¡ 'HoÃ n thÃ nh' (Ä‘Ã£ phÃª duyá»‡t trÆ°á»›c Ä‘Ã³)

    Rule chi tiáº¿t:

    1) TrÃ¹ng tá»a Ä‘á»™:
       - coord_norm giá»‘ng nhau
       - Thá»i Ä‘iá»ƒm thu tháº­p (time_norm) cá»§a PhÃª duyá»‡t > HoÃ n thÃ nh
       â†’ luÃ´n Cáº¢NH BÃO TRÃ™NG

    2) TrÃ¹ng Ä‘á»‹a chá»‰ (5 cá»™t), thá»i Ä‘iá»ƒm PhÃª duyá»‡t > HoÃ n thÃ nh:
       - Náº¿u cÃ¹ng NgÆ°á»i táº¡o â†’ Cáº¢NH BÃO TRÃ™NG
       - Náº¿u khÃ¡c NgÆ°á»i táº¡o â†’ NGHI NGá»œ TRÃ™NG

    Tráº£ vá» DataFrame gá»“m:
    - ID                : ID há»“ sÆ¡ PhÃª duyá»‡t
    - NgÆ°á»i táº¡o         : NgÆ°á»i táº¡o há»“ sÆ¡ PhÃª duyá»‡t
    - LÃ½ do trÃ¹ng       : Cáº£nh bÃ¡o / Nghi ngá» + mÃ´ táº£
    - Äá»‹a chá»‰/Tá»a Ä‘á»™ trÃ¹ng
    - ID trÃ¹ng          : cÃ¡c ID HoÃ n thÃ nh trÃ¹ng
    - NgÆ°á»i táº¡o trÃ¹ng   : ngÆ°á»i táº¡o tÆ°Æ¡ng á»©ng cÃ¡c báº£n HoÃ n thÃ nh
    """

    # Kiá»ƒm tra cÃ¡c cá»™t báº¯t buá»™c
    if "Giai Ä‘oáº¡n hiá»‡n táº¡i" not in df.columns:
        raise ValueError("Thiáº¿u cá»™t 'Giai Ä‘oáº¡n hiá»‡n táº¡i' trong file Excel.")
    if CREATOR_COL not in df.columns:
        raise ValueError(f"Thiáº¿u cá»™t '{CREATOR_COL}' trong file Excel.")
    if TIME_COL not in df.columns:
        raise ValueError(f"Thiáº¿u cá»™t '{TIME_COL}' trong file Excel.")
    if COORD_COL not in df.columns:
        raise ValueError(f"Thiáº¿u cá»™t '{COORD_COL}' trong file Excel.")
    for col in ADDR_COLS:
        if col not in df.columns:
            raise ValueError(f"Thiáº¿u cá»™t '{col}' trong file Excel.")

    # TÃ¡ch 2 nhÃ³m tráº¡ng thÃ¡i
    hoan_thanh = df[df["Giai Ä‘oáº¡n hiá»‡n táº¡i"] == "HoÃ n thÃ nh"].copy()
    phe_duyet = df[df["Giai Ä‘oáº¡n hiá»‡n táº¡i"] == "PhÃª duyá»‡t"].copy()

    # Chuáº©n hÃ³a key Ä‘á»‹a chá»‰
    hoan_thanh["addr_key"] = hoan_thanh.apply(build_addr_key, axis=1)
    phe_duyet["addr_key"] = phe_duyet.apply(build_addr_key, axis=1)

    # Chuáº©n hÃ³a tá»a Ä‘á»™
    hoan_thanh["coord_norm"] = hoan_thanh[COORD_COL].apply(normalize_coord)
    phe_duyet["coord_norm"] = phe_duyet[COORD_COL].apply(normalize_coord)

    # Chuáº©n hÃ³a thá»i gian (dd/mm/yyyy â†’ dayfirst=True)
    hoan_thanh["time_norm"] = pd.to_datetime(
        hoan_thanh[TIME_COL], dayfirst=True, errors="coerce"
    )
    phe_duyet["time_norm"] = pd.to_datetime(
        phe_duyet[TIME_COL], dayfirst=True, errors="coerce"
    )

    # Build group lookup cho HoÃ n thÃ nh (groups tráº£ vá» dict: key -> Index)
    addr_groups = hoan_thanh.groupby("addr_key").groups
    coord_groups = hoan_thanh.groupby("coord_norm").groups

    results: List[Dict[str, Any]] = []

    for _, row in phe_duyet.iterrows():
        duplicate_ids: set[Any] = set()
        duplicate_creators: set[str] = set()
        severity_levels: set[str] = set()  # {"Cáº£nh bÃ¡o trÃ¹ng", "Nghi ngá» trÃ¹ng"}
        reason_details: List[str] = []

        addr_key = row.get("addr_key")
        coord_key = row.get("coord_norm")
        creator = str(row.get(CREATOR_COL, "")).strip()
        row_time = row.get("time_norm")

        # ==============
        # Rule 2: TrÃ¹ng Ä‘á»‹a chá»‰
        # ==============
        addr_indices = addr_groups.get(addr_key)
        if addr_indices is not None and len(addr_indices) > 0:
            candidates_addr = hoan_thanh.loc[addr_indices].copy()

            # Chá»‰ láº¥y cÃ¡c há»“ sÆ¡ HoÃ n thÃ nh cÃ³ thá»i Ä‘iá»ƒm < PhÃª duyá»‡t
            if pd.notna(row_time):
                candidates_addr = candidates_addr[
                    (candidates_addr["time_norm"].notna())
                    & (candidates_addr["time_norm"] < row_time)
                ]

            if not candidates_addr.empty:
                same_creator_ids = candidates_addr[
                    candidates_addr[CREATOR_COL].astype(str).str.strip() == creator
                ]
                diff_creator_ids = candidates_addr[
                    candidates_addr[CREATOR_COL].astype(str).str.strip() != creator
                ]

                if not same_creator_ids.empty:
                    severity_levels.add("Cáº£nh bÃ¡o trÃ¹ng")
                    duplicate_ids.update(same_creator_ids["ID"].tolist())
                    duplicate_creators.update(
                        same_creator_ids[CREATOR_COL].astype(str).str.strip().tolist()
                    )
                    reason_details.append(
                        "CÃ¹ng NgÆ°á»i táº¡o vÃ  trÃ¹ng 5 thÃ´ng tin Ä‘á»‹a chá»‰ "
                        "(Tá»‰nh/ThÃ nh phá»‘, Quáº­n/Huyá»‡n/Thá»‹ xÃ£, XÃ£/PhÆ°á»ng, ÄÆ°á»ng/Phá»‘, Sá»‘ nhÃ )"
                    )

                if not diff_creator_ids.empty:
                    severity_levels.add("Nghi ngá» trÃ¹ng")
                    duplicate_ids.update(diff_creator_ids["ID"].tolist())
                    duplicate_creators.update(
                        diff_creator_ids[CREATOR_COL].astype(str).str.strip().tolist()
                    )
                    reason_details.append(
                        "KhÃ¡c NgÆ°á»i táº¡o nhÆ°ng trÃ¹ng 5 thÃ´ng tin Ä‘á»‹a chá»‰ "
                        "(Tá»‰nh/ThÃ nh phá»‘, Quáº­n/Huyá»‡n/Thá»‹ xÃ£, XÃ£/PhÆ°á»ng, ÄÆ°á»ng/Phá»‘, Sá»‘ nhÃ )"
                    )

        # ==============
        # Rule 1: TrÃ¹ng tá»a Ä‘á»™ (luÃ´n Cáº£nh bÃ¡o)
        # ==============
        coord_indices = coord_groups.get(coord_key)
        if coord_indices is not None and len(coord_indices) > 0:
            candidates_coord = hoan_thanh.loc[coord_indices].copy()

            # Chá»‰ láº¥y HoÃ n thÃ nh cÃ³ thá»i Ä‘iá»ƒm < PhÃª duyá»‡t
            if pd.notna(row_time):
                candidates_coord = candidates_coord[
                    (candidates_coord["time_norm"].notna())
                    & (candidates_coord["time_norm"] < row_time)
                ]

            if not candidates_coord.empty:
                severity_levels.add("Cáº£nh bÃ¡o trÃ¹ng")
                duplicate_ids.update(candidates_coord["ID"].tolist())
                duplicate_creators.update(
                    candidates_coord[CREATOR_COL].astype(str).str.strip().tolist()
                )
                reason_details.append("TrÃ¹ng tá»a Ä‘á»™ (Tá»a Ä‘á»™ trÃ¹ng 100% hoáº·c gáº§n Ä‘Ãºng)")

        # Náº¿u cÃ³ báº¥t ká»³ rule nÃ o khá»›p â†’ Ä‘Ã¢y lÃ  báº£n trÃ¹ng
        if duplicate_ids:
            # XÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ tá»•ng há»£p: náº¿u cÃ³ Cáº£nh bÃ¡o thÃ¬ Æ°u tiÃªn
            if "Cáº£nh bÃ¡o trÃ¹ng" in severity_levels:
                severity_label = "Cáº£nh bÃ¡o trÃ¹ng"
            else:
                severity_label = "Nghi ngá» trÃ¹ng"

            # ThÃ´ng tin trÃ¹ng: Ä‘á»‹a chá»‰ +/hoáº·c tá»a Ä‘á»™
            info_duplicated: List[str] = []
            addr_text = format_address(row)
            if addr_text:
                info_duplicated.append(f"Äá»‹a chá»‰: {addr_text}")
            coord_text = str(row.get(COORD_COL, "")).strip()
            if coord_text:
                info_duplicated.append(f"Tá»a Ä‘á»™: {coord_text}")

            results.append(
                {
                    "ID": row.get("ID"),
                    "NgÆ°á»i táº¡o": creator,
                    "LÃ½ do trÃ¹ng": f"{severity_label} â€“ " + " ; ".join(reason_details),
                    "Äá»‹a chá»‰/Tá»a Ä‘á»™ trÃ¹ng": " | ".join(info_duplicated),
                    "ID trÃ¹ng": "; ".join(str(x) for x in sorted(duplicate_ids)),
                    "NgÆ°á»i táº¡o trÃ¹ng": "; ".join(sorted(duplicate_creators)),
                }
            )

    return pd.DataFrame(results)


# ==========================
#  Streamlit App
# ==========================

def run_app() -> None:  # pragma: no cover - chá»‰ cháº¡y trÃªn Streamlit
    if st is None:
        raise RuntimeError(
            "Streamlit chÆ°a Ä‘Æ°á»£c cÃ i. HÃ£y cÃ i báº±ng:\n"
            "    pip install streamlit"
        )

    st.set_page_config(
        page_title="iFast Duplicate Checker",
        layout="wide",
    )

    st.title("ğŸ§® iFast â€“ CÃ´ng cá»¥ kiá»ƒm tra trÃ¹ng há»“ sÆ¡")

    st.markdown(
        """
        CÃ´ng cá»¥ nÃ y giÃºp kiá»ƒm tra **há»“ sÆ¡ Äáº¥t á»Ÿ** Ä‘ang á»Ÿ tráº¡ng thÃ¡i
        **â€œPhÃª duyá»‡tâ€** xem cÃ³ trÃ¹ng vá»›i cÃ¡c há»“ sÆ¡ **â€œHoÃ n thÃ nhâ€** trÆ°á»›c Ä‘Ã³ hay khÃ´ng.

        **Rule kiá»ƒm tra trÃ¹ng (tÃ³m táº¯t):**
        - TrÃ¹ng 5 thÃ´ng tin Ä‘á»‹a chá»‰  
          *(Tá»‰nh/ThÃ nh phá»‘, Quáº­n/Huyá»‡n/Thá»‹ xÃ£, XÃ£/PhÆ°á»ng, ÄÆ°á»ng/Phá»‘, Sá»‘ nhÃ )*  
          + CÃ¹ng NgÆ°á»i táº¡o â†’ **Cáº£nh bÃ¡o trÃ¹ng**  
          + KhÃ¡c NgÆ°á»i táº¡o â†’ **Nghi ngá» trÃ¹ng**  

        - TrÃ¹ng tá»a Ä‘á»™ (ká»ƒ cáº£ khi cÃ³ thÃªm/bá»›t vÃ i sá»‘ tháº­p phÃ¢n phÃ­a sau),
          vÃ  thá»i Ä‘iá»ƒm thu tháº­p sau há»“ sÆ¡ HoÃ n thÃ nh â†’ **Cáº£nh bÃ¡o trÃ¹ng**
        """
    )

    st.sidebar.header("âš™ï¸ Cáº¥u hÃ¬nh")
    asset_type = st.sidebar.selectbox(
        "Loáº¡i tÃ i sáº£n",
        ["Äáº¥t á»Ÿ", "CÄƒn há»™ chung cÆ° (chÆ°a há»— trá»£)"],
        index=0,
    )

    uploaded = st.file_uploader(
        "ğŸ“¥ Táº£i lÃªn file Excel xuáº¥t tá»« iFast (.xlsx)",
        type=["xlsx"],
    )

    if uploaded is None:
        st.info("Vui lÃ²ng táº£i lÃªn file Excel Ä‘á»ƒ báº¯t Ä‘áº§u kiá»ƒm tra.")
        return

    # Äá»c file Excel
    try:
        df = pd.read_excel(uploaded)
    except Exception as e:
        st.error(f"Lá»—i Ä‘á»c file Excel: {e}")
        return

    st.subheader("ğŸ” ThÃ´ng tin tá»•ng quan dá»¯ liá»‡u")
    with st.expander("Xem trÆ°á»›c vÃ i dÃ²ng Ä‘áº§u"):
        st.dataframe(df.head())

    if asset_type != "Äáº¥t á»Ÿ":
        st.warning("Hiá»‡n táº¡i má»›i há»— trá»£ rule cho **Äáº¥t á»Ÿ**. CÃ¡c loáº¡i khÃ¡c sáº½ Ä‘Æ°á»£c bá»• sung sau.")
        return

    # Thá»±c hiá»‡n check trÃ¹ng
    try:
        dup_df = check_duplicates(df)
    except Exception as e:
        st.error(f"Lá»—i khi kiá»ƒm tra trÃ¹ng: {e}")
        return

    st.subheader("ğŸ“Š Káº¿t quáº£ kiá»ƒm tra trÃ¹ng")

    if dup_df.empty:
        st.success("âœ… KhÃ´ng phÃ¡t hiá»‡n há»“ sÆ¡ PhÃª duyá»‡t nÃ o trÃ¹ng vá»›i HoÃ n thÃ nh.")
    else:
        st.write(f"ğŸ”´ PhÃ¡t hiá»‡n **{len(dup_df)}** há»“ sÆ¡ PhÃª duyá»‡t cÃ³ dáº¥u hiá»‡u trÃ¹ng.")
        st.dataframe(dup_df, use_container_width=True)

        # NÃºt download CSV
        buffer = io.StringIO()
        dup_df.to_csv(buffer, index=False)
        st.download_button(
            label="â¬‡ï¸ Táº£i vá» danh sÃ¡ch trÃ¹ng (CSV)",
            data=buffer.getvalue(),
            file_name="detected_duplicates.csv",
            mime="text/csv",
        )


# Khi cháº¡y báº±ng `streamlit run duplicate_checker.py`
if __name__ == "__main__":  # pragma: no cover
    if st is not None:
        run_app()
    else:
        # Cho phÃ©p cháº¡y python duplicate_checker.py Ä‘á»ƒ test nhanh khÃ´ng cáº§n streamlit
        print(
            "Module loaded. ÄÃ¢y lÃ  file dÃ nh cho Streamlit.\n"
            "Äá»ƒ cháº¡y app, dÃ¹ng:\n"
            "    streamlit run duplicate_checker.py"
        )
